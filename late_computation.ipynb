{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOlxCEPjXEQ7","executionInfo":{"status":"ok","timestamp":1674061338651,"user_tz":-60,"elapsed":825509,"user":{"displayName":"Wairimu Muriga","userId":"06531174956711289443"}},"outputId":"fd3688ad-5e94-4c20-97e8-67a22e3d3d4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","======================================= Loading the dataset ========================================\n","\t -Number of GeoLocation                              5264\n","\t -Number of Images per GeoLocation                   39\n","====================================== Splitting the dataset =======================================\n","\t -Number of GeoLocation (training)                   4212\n","\t -Number of GeoLocation (validation)                 1052\n","======================================== Building the Model ========================================\n","Model: \"TDCNN\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 6, None, None, 1  0         \n","                             )]                                  \n","                                                                 \n"," time_distributed (TimeDistr  (None, 6, None, None, 64  640      \n"," ibuted)                     )                                   \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, 6, None, None, 64  256      \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_2 (TimeDis  (None, 6, None, None, 64  36928    \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_3 (TimeDis  (None, 6, None, None, 64  256      \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_4 (TimeDis  (None, 6, None, None, 64  36928    \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_5 (TimeDis  (None, 6, None, None, 64  256      \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_6 (TimeDis  (None, 6, None, None, 64  36928    \n"," tributed)                   )                                   \n","                                                                 \n"," time_distributed_7 (TimeDis  (None, 6, None, None, 64  256      \n"," tributed)                   )                                   \n","                                                                 \n"," conv_lstm2d (ConvLSTM2D)    (None, None, None, 64)    295168    \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, None, None, 1)     577       \n","                                                                 \n","=================================================================\n","Total params: 408,193\n","Trainable params: 407,681\n","Non-trainable params: 512\n","_________________________________________________________________\n","None\n","======================================== Training the Model ========================================\n"]}],"source":["import numpy as np\n","from google.colab import drive\n","import sys\n","from PIL import Image\n","import os\n","from os import listdir\n","import keras\n","\n","! pip install rasterio 1>/dev/null\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/MyDrive/sen2dwater/USANNIOMIT')\n","\n","from dataio.datahandler import datahandler\n","from dataio.datareader import datareader\n","\n","from dataio.datahandler import datahandler\n","from dataio.datareader import datareader\n","# from models.LSTMv1 import LSTMv1\n","# from models.BLSTMv1 import BLSTMv1\n","from models.TDCNNv1 import TDCNNv1\n","\n","# from utils.plot_dataset import plot_series \n","\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","import os\n","\n","%matplotlib inline\n","\n","\n","# sys.path.append('/content/drive/MyDrive/results-lenovo')\n","\n","path_to_ndvi_images = '/content/drive/MyDrive/results-lenovo/TDCNNv1/ndvi/res/pr/epoch-14'\n","path_to_ndwi_images = '/content/drive/MyDrive/results-lenovo/TDCNNv1/ndwi/res/pr/epoch-14'\n","path_to_nddi_images = '/content/drive/MyDrive/results-lenovo/TDCNNv1/nddi/res/pr/epoch-14'\n","\n","\n","def compute_NDDI(NDWI,NDVI):\n","    '''\n","        Calculates the normalized difference betweeen two indices.\n","\n","        Inputs:\n","            - NDWI: NDWI image as computed by normalized_difference method. Must be a numpy\n","                    array (W,H,B) width W, height H and B bands\n","            - NDVI: NDVI image as computed by normalized_difference method. Must be a numpy\n","                    array (W,H,B) width W, height H and B bands\n","        Output:\n","            - NDDI: normalized difference of NDWI and NDVI bands \n","        ------------------------------------------------------------------------\n","        The formula applied is the following\n","\n","                            nd = (NDVI - NDWI)/((NDVI + NDWI) + e)\n","\n","        e ~= 0.00001 to stabilize division with weak denominator.\n","    '''\n","    return (NDVI - NDWI) / (NDVI + NDWI + 0.00001)\n","\n","#======================================= Loading the dataset ========================================\n","# dataset_root_path = '/content/drive/MyDrive/sen2dwater/USANNIOMIT/DATASET_2016_2022'\n","dataset_root_path = '/content/drive/MyDrive/SEN2DWATER'\n","\n","dh       = datahandler(dataset_root_path)\n","keys     = list(dh.paths.keys())\n","t_len    = len(dh.paths[keys[0]])\n","\n","print('{:=^100}'.format(' Loading the dataset '))\n","print('\\t -{:<50s} {}'.format('Number of GeoLocation', len(keys)))\n","print('\\t -{:<50s} {}'.format('Number of Images per GeoLocation', t_len))\n","\n","#========================================== Split dataset ===========================================\n","train_set, val_set = dh.split(SPLIT_FACTOR)\n","print('{:=^100}'.format(' Splitting the dataset '))\n","print('\\t -{:<50s} {}'.format('Number of GeoLocation (training)', len(train_set.keys())))\n","print('\\t -{:<50s} {}'.format('Number of GeoLocation (validation)', len(val_set.keys())))\n","\n","tdcnnv1 = TDCNNv1(shape=(T_LEN, PATCH_WIDTH, PATCH_HEIGHT, BANDS))\n","print('{:=^100}'.format(' Building the Model '))\n","print(tdcnnv1.model.summary())\n","#========================================== Train model =============================================\n","print('{:=^100}'.format(' Training the Model '))\n","# history = tdcnnv1.train(train_set, val_set, normalize = True)\n","\n","tdcnnv1.generateData(train_set, val_set)"]},{"cell_type":"code","source":["ndvi_list = []\n","ndwi_list = []\n","computed_nddi_list = []\n","gt_nddi_list = []\n","\n","\n","def load(path):\n","  out = []\n","  for image in os.listdir(path):\n","    np_image = np.asarray(Image.open(path + \"/\" + image))\n","    out.append(np_image)\n","  return out\n","\n","ndvi_list = load(path_to_ndvi_images)\n","ndwi_list = load(path_to_ndwi_images)\n","gt_nddi_list = load(path_to_nddi_images)\n","\n","print(len(ndvi_list))\n","print(len(ndwi_list))\n","\n","for i in range(100):\n","  # compute_NDDI(NDWI,NDVI)\n","  # for each predicted ndwi and ndvi image, calculate the nddi value\n","  computed_nddi = compute_NDDI(ndwi_list[i], ndvi_list[i])\n","  # store in array\n","  computed_nddi_list.append(computed_nddi)\n","\n","\n","# print(computed_nddi_list[0] - gt_nddi_list[0])\n","# print(computed_nddi_list[0])\n","# print(gt_nddi_list[0])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8SB1i0LXkTQ","executionInfo":{"status":"ok","timestamp":1674056146563,"user_tz":-60,"elapsed":9838,"user":{"displayName":"Wairimu Muriga","userId":"06531174956711289443"}},"outputId":"68ef77fb-0cae-4881-c0f8-8130a9d3b640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n","100\n","[[[2.55319122e+00 1.69999660e+01 2.03333164e+01 0.00000000e+00]\n","  [2.83333300e+00 1.16666472e+01 1.37777701e+01 0.00000000e+00]\n","  [2.90588201e+00 2.99999864e+00 1.74285590e+01 0.00000000e+00]\n","  ...\n","  [1.88721790e+00 5.61983448e-01 9.99999959e-01 0.00000000e+00]\n","  [2.03999984e+00 3.89998700e+01 9.36254943e-01 0.00000000e+00]\n","  [4.05405378e-02 6.72413764e-01 1.08888884e+00 0.00000000e+00]]\n","\n"," [[2.09433943e+00 5.59633002e-01 1.96078424e-02 0.00000000e+00]\n","  [3.81679360e-02 4.03331989e+01 9.43319800e-01 0.00000000e+00]\n","  [2.32710259e+00 9.59999040e+00 4.77999044e+01 0.00000000e+00]\n","  ...\n","  [1.92982439e-01 2.02438975e+00 8.89763744e-01 0.00000000e+00]\n","  [1.40845061e-01 7.49999531e+00 9.25311165e-01 0.00000000e+00]\n","  [1.16564410e-01 7.46724858e-01 1.16267937e+00 0.00000000e+00]]\n","\n"," [[6.57894694e-02 6.47058796e-01 1.06222218e+00 0.00000000e+00]\n","  [2.19266035e+00 4.29718858e-01 6.09998475e+01 0.00000000e+00]\n","  [2.88235260e+00 3.52631393e+00 1.74285590e+01 0.00000000e+00]\n","  ...\n","  [2.91666636e-01 7.39130328e-01 2.30000000e+07 0.00000000e+00]\n","  [2.71186418e-01 1.44444418e+00 8.87999964e-01 0.00000000e+00]\n","  [2.65822768e-01 4.17241235e+00 9.05172375e-01 0.00000000e+00]]\n","\n"," ...\n","\n"," [[6.04026805e-02 6.24999974e-01 1.03493445e+00 0.00000000e+00]\n","  [1.96610153e+00 6.49769555e-01 2.07468871e-02 0.00000000e+00]\n","  [1.82014375e+00 8.09523771e-01 4.67289698e-02 0.00000000e+00]\n","  ...\n","  [2.85714259e-02 1.81818165e-02 1.05833329e+00 0.00000000e+00]\n","  [1.08695640e-01 6.93069238e-02 1.00806448e+00 0.00000000e+00]\n","  [5.12820447e-02 4.44444395e-02 2.54000000e+07 0.00000000e+00]]\n","\n"," [[1.94573628e+00 5.28455263e-01 9.75609716e-01 0.00000000e+00]\n","  [1.96610153e+00 6.12612585e-01 4.08163249e-03 0.00000000e+00]\n","  [2.04678351e-01 4.96665011e+01 9.90950181e-01 0.00000000e+00]\n","  ...\n","  [2.06306288e+00 2.17117098e+00 6.32911366e-02 0.00000000e+00]\n","  [1.86813166e-01 1.31313118e-01 9.91935444e-01 0.00000000e+00]\n","  [2.30769201e-01 3.33333291e-01 8.03330656e+01 0.00000000e+00]]\n","\n"," [[2.02247180e-01 6.80327841e-01 1.08653841e+00 0.00000000e+00]\n","  [2.06896540e-01 9.24528258e-01 0.00000000e+00 0.00000000e+00]\n","  [6.57894694e-02 6.61016921e-01 1.07142852e+00 0.00000000e+00]\n","  ...\n","  [1.69811305e-01 1.00917422e-01 1.02499996e+00 0.00000000e+00]\n","  [2.94117604e-02 2.49999969e-02 4.23332628e+01 0.00000000e+00]\n","  [1.50684911e-01 4.11764645e-01 2.69999700e+01 0.00000000e+00]]]\n","[[[233 228  25 255]\n","  [250 230  34 255]\n","  [250 230  34 255]\n","  ...\n","  [ 64  67 135 255]\n","  [ 68   3  87 255]\n","  [ 69   5  88 255]]\n","\n"," [[248 230  33 255]\n","  [250 230  34 255]\n","  [250 230  34 255]\n","  ...\n","  [207 225  28 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]]\n","\n"," [[ 33 167 132 255]\n","  [250 230  34 255]\n","  [250 230  34 255]\n","  ...\n","  [250 230  34 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]]\n","\n"," ...\n","\n"," [[ 68   3  87 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  ...\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]]\n","\n"," [[ 68   3  87 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  ...\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]]\n","\n"," [[ 69   6  90 255]\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  ...\n","  [ 68   3  87 255]\n","  [ 68   3  87 255]\n","  [ 69   6  90 255]]]\n"]}]},{"cell_type":"code","source":["path_to_gt_ndvi_images = '/content/drive/MyDrive/results-lenovo/TDCNNv1/ndvi/res/gt/epoch-36'\n","\n","ndvi_model = keras.models.load_model('/content/drive/MyDrive/results-lenovo/ndvi_model.h5')\n","print(type(ndvi_model))\n","ndvi_model.predict()\n","# his = ndvi_model.fit()\n","# print(his.params)\n","\n","# for image in os.listdir(path_to_gt_ndvi_images):\n","#   np_image = np.asarray(Image.open(path_to_gt_ndvi_images + \"/\" + image))\n","#   ndvi_model.predict(np_image)\n","\n"],"metadata":{"id":"eIPugxUMcfxO","colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"status":"error","timestamp":1674060332675,"user_tz":-60,"elapsed":812,"user":{"displayName":"Wairimu Muriga","userId":"06531174956711289443"}},"outputId":"1fc543ab-701e-46df-9a83-b5949d80b84c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'keras.engine.functional.Functional'>\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-53b5918feea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mndvi_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/results-lenovo/ndvi_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mndvi_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# his = ndvi_model.fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(his.params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'model'"]}]},{"cell_type":"code","source":["from IPython.core.interactiveshell import re\n","ndwiimg = \"/content/pt-1.tiff\"\n","ndviimg = \"/content/pt-0.tiff\"\n","\n","ndwi_image = np.asarray(Image.open(ndwiimg))\n","ndvi_image = np.asarray(Image.open(ndviimg))\n","\n","res = compute_NDDI(ndwi_image, ndvi_image)\n","print(res)\n","print(gt_nddi_list[0])"],"metadata":{"id":"VLyjuF-lzvP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xTWGafJQ-rCs"},"execution_count":null,"outputs":[]}]}