{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 44634,
     "status": "error",
     "timestamp": 1674062397704,
     "user": {
      "displayName": "Wairimu Muriga",
      "userId": "06531174956711289443"
     },
     "user_tz": -60
    },
    "id": "HeWVwpDaRrOb",
    "outputId": "c6ad15e4-ac0f-4ada-ceb4-631f28919a3d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h2caF77GR_cr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:53:17.576731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dataio.datahandler import datahandler\n",
    "from dataio.datareader import datareader\n",
    "\n",
    "from dataio.datahandler import datahandler\n",
    "from dataio.datareader import datareader\n",
    "# from models.LSTMv1 import LSTMv1\n",
    "# from models.BLSTMv1 import BLSTMv1\n",
    "from models.TDCNNv1 import TDCNNv1\n",
    "\n",
    "# from utils.plot_dataset import plot_series \n",
    "\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import sklearn.preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(model):\n",
    "    dataset_root_path = '/home/veronica/SEN2DWATER'\n",
    "\n",
    "    dh = datahandler(dataset_root_path)\n",
    "    keys = list(dh.paths.keys())\n",
    "    t_len = len(dh.paths[keys[0]])\n",
    "    \n",
    "    print(\"datahandler done\")\n",
    "\n",
    "    LEN_SERIES = t_len\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (4*LEN_SERIES, 4))\n",
    "\n",
    "    axes[0].plot(model.history.loss, label = 'training loss')\n",
    "    axes[0].plot(model.history['val_loss'], label = 'validation loss')\n",
    "    axes[0].set_title('Huber Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(model.history['mae'], label = 'training MAE')\n",
    "    axes[1].plot(model.history['val_mae'], label = 'validation MAE')\n",
    "    axes[1].set_title('MAE')\n",
    "    axes[1].legend()\n",
    "\n",
    "    axes[2].plot(model.history['mse'], label = 'training MSE')\n",
    "    axes[2].plot(model.history['val_mse'], label = 'validation MSE')\n",
    "    axes[2].set_title('MSE')\n",
    "    axes[2].legend()\n",
    "    plt.savefig(name + 'Training.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:53:19.138814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 11:53:19.140319: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# import trained models \n",
    "# ndwi_model = load_model('/content/drive/MyDrive/sen2dwater/USANNIOMIT/ndwi_model2.h5')\n",
    "ndwi_model = load_model('/home/veronica/USANNIOMIT/ndwi_model2.h5')\n",
    "\n",
    "# ndvi_model = load_model('//content/drive/MyDrive/sen2dwater/USANNIOMIT/ndvi_model2.h5')\n",
    "ndvi_model = load_model('/home/veronica/USANNIOMIT/ndvi_model2.h5')\n",
    "\n",
    "# nddi_model = load_model('/content/drive/MyDrive/sen2dwater/USANNIOMIT/nddi_model2.h5')\n",
    "# nddi_model = load_model('/content/drive/MyDrive/results-lenovo2/nddi_model2.h5')\n",
    "nddi_model = load_model('/home/veronica/USANNIOMIT/nddi_model.model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(model = nddi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nV9f_D4fUWw0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# #======================================= Loading the dataset ========================================\n",
    "# # dataset_root_path = '/content/drive/MyDrive/sen2dwater/USANNIOMIT/DATASET_2016_2022'\n",
    "# dataset_root_path = '/home/veronica/SEN2DWATER'\n",
    "\n",
    "# dh       = datahandler(dataset_root_path)\n",
    "# keys     = list(dh.paths.keys())\n",
    "# t_len    = len(dh.paths[keys[0]])\n",
    "\n",
    "# print('{:=^100}'.format(' Loading the dataset '))\n",
    "# print('\\t -{:<50s} {}'.format('Number of GeoLocation', len(keys)))\n",
    "# print('\\t -{:<50s} {}'.format('Number of Images per GeoLocation', t_len))\n",
    "\n",
    "# #========================================== Split dataset ===========================================\n",
    "# train_set, val_set = dh.split(SPLIT_FACTOR)\n",
    "# print('{:=^100}'.format(' Splitting the dataset '))\n",
    "# print('\\t -{:<50s} {}'.format('Number of GeoLocation (training)', len(train_set.keys())))\n",
    "# print('\\t -{:<50s} {}'.format('Number of GeoLocation (validation)', len(val_set.keys())))\n",
    "\n",
    "# tdcnnv1 = TDCNNv1(shape=(T_LEN, PATCH_WIDTH, PATCH_HEIGHT, BANDS))\n",
    "# print('{:=^100}'.format(' Building the Model '))\n",
    "# print(tdcnnv1.model.summary())\n",
    "# #========================================== Train model =============================================\n",
    "# print('{:=^100}'.format(' Training the Model '))\n",
    "# # history = tdcnnv1.train(train_set, val_set, normalize = True)\n",
    "\n",
    "# tdcnnv1.generateData(train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nP0kzJXoyoy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns2tnOCavwvU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leEeejxzwI_Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
